{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearningProject-Group2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGxmGfMjXmcp"
      },
      "source": [
        "# **Deep Learning Project** - Aerial Perspective Object Detection\n",
        "SEP 769 - Group 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQmKNgA_GVld",
        "outputId": "6fa42832-1736-41cc-fdb3-4d0e602c8adc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#About semantic segmentation: https://www.jeremyjordan.me/semantic-segmentation/\n",
        "#TF Tutorial: https://www.tensorflow.org/tutorials/images/segmentation\n",
        "#TF load and process images: https://www.tensorflow.org/tutorials/load_data/images\n",
        "\n",
        "#Different image nets: https://medium.com/analytics-vidhya/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5\n",
        "#TF Resnet: \n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "drive.mount('/content/gdrive')\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "import fnmatch\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "if not os.path.exists(\"/content/gdrive/Shareddrives/SEP_769/data/drone_data/\"):\n",
        "  !unzip \"/content/gdrive/Shareddrives/SEP_769/drone_data.zip\" -d \"/content/gdrive/Shareddrives/SEP_769/data\"\n",
        "\n",
        "#image1 = cv2.imread('{}000.jpg'.format(original_images_path)) #original size image\n",
        "#image2 = cv2.resize(cv2.imread('{}000.jpg'.format(original_images_path), flags=1), (0,0), fx=0.05, fy=0.05)  #smaller image\n",
        "#print(image1.shape)\n",
        "#print(image2.shape)\n",
        "\n",
        "#print('\\nTotal of {} images at path: \\n{}\\n\\n'.format(image_count, original_images_path))\n",
        "\n",
        "#40 for test\n",
        "#360 for train\n",
        "\n",
        "#pixel accuracy, Intersection over Union (IOU)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBDOq0y71fY-"
      },
      "source": [
        "#*Constants and Functions*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnNjZk9Y1euR"
      },
      "source": [
        "original_images_path = '/content/gdrive/Shareddrives/SEP_769/data/drone_data/original_images/'\n",
        "original_semantic_path = '/content/gdrive/Shareddrives/SEP_769/data/drone_data/label_images_semantic/'\n",
        "HEIGHT = 200\n",
        "WIDTH = 300\n",
        "EPOCHS = 50\n",
        "BATCHSIZE = 3\n",
        "VAL_SPLIT = 0.9\n",
        "\n",
        "# reads images from dir, resizes and returns np array\n",
        "# optional file type argument ext\n",
        "def images_to_array(dir, width, height, ext='.jpg'):\n",
        "  data = []\n",
        "  files = os.listdir(dir)\n",
        "  files.sort()\n",
        "  for filename in files:\n",
        "    if filename.endswith(ext):\n",
        "      img = cv2.imread(dir+filename,flags=1)\n",
        "      img = cv2.resize(img, (width, height))\n",
        "      data.append(img)\n",
        "\n",
        "  return np.array(data)\n",
        "\n",
        "def labels_to_array(dir, width, height, ext='.jpg'):\n",
        "  data = []\n",
        "  files = os.listdir(dir)\n",
        "  files.sort()\n",
        "  for filename in files:\n",
        "    if filename.endswith(ext):\n",
        "      img = cv2.imread(dir+filename,flags=0)\n",
        "      img = cv2.resize(img, (width, height))\n",
        "      data.append(img)\n",
        "\n",
        "  return np.array(data)\n",
        "\n",
        "# displays a number of originals with their masks\n",
        "def display_images(images):\n",
        "  plt.figure(figsize=(15,10))\n",
        "  for i in range(len(images)):\n",
        "    plt.subplot(1, len(images), i + 1)\n",
        "    if len(images[i].shape) == 3:\n",
        "      plt.imshow(images[i])\n",
        "    else:\n",
        "      plt.imshow(images[i], cmap=\"gray\", vmin=0, vmax=255)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "#plt.imshow(original_images[0])\n",
        "#plt.show()\n",
        "#print(original_images[0].shape)\n",
        "#plt.imshow(semantic_images[0])\n",
        "#plt.show()\n",
        "#print(semantic_images[0].shape) "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpEq2q4K6g35"
      },
      "source": [
        "#Prepping Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxTrtxZu6fY1",
        "outputId": "42682248-9246-4e9c-9dd7-89ab3d988b0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "images = images_to_array(original_images_path, width=WIDTH, height=HEIGHT)\n",
        "print(images.shape)\n",
        "\n",
        "labels = labels_to_array(original_semantic_path, width=WIDTH, height=HEIGHT, ext='png')\n",
        "print(labels.shape)\n",
        "\n",
        "\n",
        "\n",
        "#Old Image Import\n",
        "#original_images = [cv2.resize(cv2.imread(file, flags=1), (0,0), fx=0.05, fy=0.05) for file in glob.glob('{}*.jpg'.format(original_images_path))]  #importing images in color at 5% scale\n",
        "#semantic_images = [cv2.resize(cv2.imread(file, flags=0), (0,0), fx=0.05, fy=0.05) for file in glob.glob('{}*.png'.format(original_semantic_path))]  #importing images segmented\n",
        "#print(original_images.shape)\n",
        "#print(semantic_images.shape)\n",
        "\n",
        "#image_count = len(fnmatch.filter(os.listdir(original_images_path), '*.jpg'))\n",
        "#print('\\nTotal of {} images at path: \\n{}\\n\\n'.format(image_count, original_images_path))\n",
        "#image_count = len(fnmatch.filter(os.listdir(original_semantic_path), '*.png'))\n",
        "#print('\\nTotal of {} images at path: \\n{}\\n\\n'.format(image_count, original_semantic_path))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(400, 200, 300, 3)\n",
            "(400, 200, 300, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMLryDedHlOc",
        "outputId": "9a82b8e1-34ac-42da-81d1-083d88b4abbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_images, test_images = tf.split(images, [360,40])\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)\n",
        "\n",
        "train_labels, test_labels = tf.split(labels, [360,40])\n",
        "print(train_labels.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(360, 200, 300, 3)\n",
            "(40, 200, 300, 3)\n",
            "(360, 200, 300, 3)\n",
            "(40, 200, 300, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH6WuC_v-Xkb"
      },
      "source": [
        "#Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WXftyA9-cGS"
      },
      "source": [
        "for i in range(10):\n",
        "  display_images([images[i], labels[i]])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}