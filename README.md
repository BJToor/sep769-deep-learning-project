# sep769-deep-learning-project (Group 2)
SEP 769 (Cyber Physical Systems) Deep Learning Project, Project 3 - Aerial Perspective Object Detection (Group 2)

Based on the dataset resource (Kaggle): https://www.kaggle.com/bulentsiyah/semantic-drone-dataset

Additional information on the dataset is available at https://www.tugraz.at/index.php?id=22387



Project 3: Aerial Perspective Object Detection

As described by the references listed above:

Description
Drone and aerial picture-taking quality has improved drastically in the past decade. Drone stabilization allows pictures taken from an aerial view to be crystal clear without shaking or blurriness. This has many practical and exciting applications for photography, cinematography, and also image recognition! Drone images can be used to quickly identify people and seek out specific objects in a large area. Think of how this could be used for spotting survivor rescues in disaster-struck areas.

The Semantic Drone Dataset focuses on semantic understanding of urban scenes for increasing the safety of autonomous drone flight and landing procedures. The imagery depicts more than 20 houses from nadir (bird's eye) view acquired at an altitude of 5 to 30 meters above the ground. A high-resolution camera was used to obtain images at a size of 6000x4000px (24Mpx).

The dataset consists of 400 images that have been annotated according to twenty standard classes such as trees, persons, cars, and pavement.


Outcomes:

- Identify everyday objects such as cars and roads in bird's eye view images
- Use a trained model to identify objects over a large, continuous, mapped area (i.e., your local neighborhood from google maps)
- Use the positioning of cars and people determined to flag areas where pedestrians may be at most risk of an accident
